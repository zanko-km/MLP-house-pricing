{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eebcab60-4ea0-40cd-9a60-5a4ec8cd3b39",
   "metadata": {},
   "source": [
    "<h1>Importing libraries</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8817a19b-3287-4142-9977-2861b901d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ced073-f7df-4477-bf4e-f66ede7e8b4f",
   "metadata": {},
   "source": [
    "<h1>A</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e674fcb8-61df-48d8-8bb8-d0567797460b",
   "metadata": {},
   "source": [
    "<b>If we have missing values we have diffrent methods to handle it<br>1- we can simply `delete` them it is simple and do not add artificial data but it may contains important informations and reduce data<br>2- we can replace it with`mean or median or mod` it is very simple but also reduce acuraccy <br>3- we can use `KNN or regression` it have more acuraccy and holding data structure but it is more complicated<br>4- we can use methods based on `deep learning` like `Auto encoders` it is very high acurate and can cosidering non-linear relations but it needs a lot of data to train and it is very hard to implement</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58acb3b6-8ce1-4832-8f55-bc01edf6b2db",
   "metadata": {},
   "source": [
    "<h1>B</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9583849-fcfe-4021-bedc-0251a56d28ec",
   "metadata": {},
   "source": [
    "<b>I just make it `None` or `NA `or `zero` because in descrepsion said we must have these type of datas but they are missed in data set then delete every data remain<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e4fbb037-16a9-4194-8e58-db5c8d7f17bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotFrontage     18.590998\n",
      "Alley           93.542074\n",
      "MasVnrType      57.729941\n",
      "MasVnrArea       0.293542\n",
      "BsmtQual         2.544031\n",
      "BsmtCond         2.544031\n",
      "BsmtExposure     2.544031\n",
      "BsmtFinType1     2.544031\n",
      "BsmtFinType2     2.544031\n",
      "Electrical       0.097847\n",
      "FireplaceQu     47.651663\n",
      "GarageType       5.283757\n",
      "GarageYrBlt      5.283757\n",
      "GarageFinish     5.283757\n",
      "GarageQual       5.283757\n",
      "GarageCond       5.283757\n",
      "PoolQC          99.510763\n",
      "Fence           80.234834\n",
      "MiscFeature     96.086106\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "missing_percent = df_train.isnull().sum() * 100 / len(df_train)\n",
    "missing_percent = missing_percent[missing_percent > 0]\n",
    "print(missing_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a3e91637-b788-433c-9102-c60b88fa5baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['LotFrontage'] = df_train['LotFrontage'].fillna(0)\n",
    "df_train['MasVnrArea'] = df_train['MasVnrArea'].fillna(0)\n",
    "df_train['GarageCars'] = df_train['GarageCars'].fillna(0)\n",
    "df_train['GarageArea'] = df_train['GarageArea'].fillna(0)\n",
    "df_train['Alley'] = df_train['Alley'].fillna('None')\n",
    "df_train['MasVnrType'] = df_train['MasVnrType'].fillna('None')\n",
    "df_train['PoolQC'] = df_train['PoolQC'].fillna('NA')\n",
    "df_train['Fence'] = df_train['Fence'].fillna('NA')\n",
    "df_train['MiscFeature'] = df_train['MiscFeature'].fillna('NA')\n",
    "df_train['FireplaceQu'] = df_train['FireplaceQu'].fillna('NA')\n",
    "df_train['BsmtQual'] = df_train['BsmtQual'].fillna('NA')\n",
    "df_train['BsmtCond'] = df_train['BsmtCond'].fillna('NA')\n",
    "df_train['BsmtExposure'] = df_train['BsmtExposure'].fillna('NA')\n",
    "df_train['BsmtFinType1'] = df_train['BsmtFinType1'].fillna('NA')\n",
    "df_train['BsmtFinSF1'] = df_train['BsmtFinSF1'].fillna('NA')\n",
    "df_train['BsmtFinType2'] = df_train['BsmtFinType2'].fillna('NA')\n",
    "df_train['BsmtFinSF2'] = df_train['BsmtFinSF2'].fillna('NA')\n",
    "df_train['BsmtUnfSF'] = df_train['BsmtUnfSF'].fillna('NA')\n",
    "df_train['GarageType'] = df_train['GarageType'].fillna('NA')\n",
    "df_train['GarageYrBlt'] = df_train['GarageYrBlt'].fillna('NA')\n",
    "df_train['GarageFinish'] = df_train['GarageFinish'].fillna('NA')\n",
    "df_train['GarageQual'] = df_train['GarageQual'].fillna('NA')\n",
    "df_train['GarageCond'] = df_train['GarageCond'].fillna('NA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ad05ad0f-21c9-4666-9e74-18ef959796f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['LotFrontage'] = df_test['LotFrontage'].fillna(0)\n",
    "df_test['MasVnrArea'] = df_test['MasVnrArea'].fillna(0)\n",
    "df_test['GarageCars'] = df_test['GarageCars'].fillna(0)\n",
    "df_test['GarageArea'] = df_test['GarageArea'].fillna(0)\n",
    "df_test['Alley'] = df_test['Alley'].fillna('None')\n",
    "df_test['MasVnrType'] = df_test['MasVnrType'].fillna('None')\n",
    "df_test['PoolQC'] = df_test['PoolQC'].fillna('NA')\n",
    "df_test['Fence'] = df_test['Fence'].fillna('NA')\n",
    "df_test['MiscFeature'] = df_test['MiscFeature'].fillna('NA')\n",
    "df_test['FireplaceQu'] = df_test['FireplaceQu'].fillna('NA')\n",
    "df_test['BsmtQual'] = df_test['BsmtQual'].fillna('NA')\n",
    "df_test['BsmtCond'] = df_test['BsmtCond'].fillna('NA')\n",
    "df_test['BsmtExposure'] = df_test['BsmtExposure'].fillna('NA')\n",
    "df_test['BsmtFinType1'] = df_test['BsmtFinType1'].fillna('NA')\n",
    "df_test['BsmtFinSF1'] = df_test['BsmtFinSF1'].fillna('NA')\n",
    "df_test['BsmtFinType2'] = df_test['BsmtFinType2'].fillna('NA')\n",
    "df_test['BsmtFinSF2'] = df_test['BsmtFinSF2'].fillna('NA')\n",
    "df_test['BsmtUnfSF'] = df_test['BsmtUnfSF'].fillna('NA')\n",
    "df_test['GarageType'] = df_test['GarageType'].fillna('NA')\n",
    "df_test['GarageYrBlt'] = df_test['GarageYrBlt'].fillna('NA')\n",
    "df_test['GarageFinish'] = df_test['GarageFinish'].fillna('NA')\n",
    "df_test['GarageQual'] = df_test['GarageQual'].fillna('NA')\n",
    "df_test['GarageCond'] = df_test['GarageCond'].fillna('NA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "eb83a31d-3026-41fe-bf45-523db4f547b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(inplace=True)\n",
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86718ea9-8dd8-4832-8569-68d88b3c26e2",
   "metadata": {},
   "source": [
    "<h1>C</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847ef7fd-5083-4ba0-a7b9-bffe85c4a610",
   "metadata": {},
   "source": [
    "<b>In this data set beside ID we don't have features that is not unuseable or if it is in MLP it gets low weight</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e728b-93bd-4464-bdc3-561579b7d899",
   "metadata": {},
   "source": [
    "<h1>D</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3f214fbb-3a26-42be-a776-39e663589c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_2 = pd.get_dummies(df_train, drop_first=True)\n",
    "df_test_2 = pd.get_dummies(df_test, drop_first=True)\n",
    "df_train_encode, df_test_encode = df_train_2.align(df_test_2, join=\"left\", axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b85a172c-5789-4f1b-9118-9f090414103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_encode.drop(columns=['SalePrice']).values\n",
    "y_train = df_train_encode['SalePrice'].values\n",
    "X_test = df_test_encode.drop(columns=['SalePrice']).values\n",
    "y_test = df_test['SalePrice'].values\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b969d85-6baa-4aae-96af-4502fbe0f11d",
   "metadata": {},
   "source": [
    "<h1>E</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3dadc706-eb37-4ea0-a2b3-70cd1502566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden = nn.Linear(input_size, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.hidden(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b021e646-8123-4969-97e5-f277839d6fcd",
   "metadata": {},
   "source": [
    "<h1>F</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b542fd4d-d572-4dc6-b123-6f07b701fbdc",
   "metadata": {},
   "source": [
    "<h2>RMSE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f327d89e-365d-451c-ac5b-10416210ddf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 38903488512.0000\n",
      "Epoch 100, Loss: 3742782976.0000\n",
      "Epoch 200, Loss: 1252130944.0000\n",
      "Epoch 300, Loss: 785393024.0000\n",
      "Epoch 400, Loss: 526836640.0000\n",
      "Epoch 500, Loss: 371081248.0000\n",
      "Epoch 600, Loss: 278190048.0000\n",
      "Epoch 700, Loss: 220463040.0000\n",
      "Epoch 800, Loss: 181212464.0000\n"
     ]
    }
   ],
   "source": [
    "input_size = X_train_tensor.shape[1]\n",
    "hidden_size = 50\n",
    "output_size = 1\n",
    "learning_rate = 0.1\n",
    "epochs = 900\n",
    "\n",
    "model = MLP(input_size, hidden_size, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_train_tensor)\n",
    "    loss = criterion(y_pred, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bb5e4bf8-f4d1-4865-87e2-f8bb87139401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 37824.9062\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test_tensor)\n",
    "    mse = criterion(y_test_pred, y_test_tensor)\n",
    "    rmse = torch.sqrt(mse).item()\n",
    "\n",
    "print(f\"Test RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bad9b7-17d8-488d-86c6-b2139686b17a",
   "metadata": {},
   "source": [
    "<h2>MAE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "000aae74-62cc-4264-a13c-aebe652ec93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 181326.1562\n",
      "Epoch 100, Loss: 47105.8203\n",
      "Epoch 200, Loss: 19436.1133\n",
      "Epoch 300, Loss: 12499.7910\n",
      "Epoch 400, Loss: 8802.8389\n",
      "Epoch 500, Loss: 6554.5513\n",
      "Epoch 600, Loss: 5264.0112\n",
      "Epoch 700, Loss: 4422.5190\n",
      "Epoch 800, Loss: 3926.4336\n"
     ]
    }
   ],
   "source": [
    "input_size = X_train_tensor.shape[1]\n",
    "hidden_size = 50\n",
    "output_size = 1\n",
    "learning_rate = 0.1\n",
    "epochs = 900\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = MLP(input_size, hidden_size, output_size)\n",
    "criterion = nn.L1Loss()  # Mean Squared Error loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Stochastic Gradient Descent\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_train_tensor)\n",
    "    loss = criterion(y_pred, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "792ddcaf-0cb3-40bc-8f62-1860032805ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 25816.0449\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test_tensor)\n",
    "    mae = criterion(y_test_pred, y_test_tensor).item()\n",
    "print(f\"Test MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ade05f-7b9d-4ca8-b2b8-c93dfefff82a",
   "metadata": {},
   "source": [
    "<h2>MAPE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dc328a0b-1bba-4dd5-824e-71f2571f9d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 181326.0156\n",
      "Epoch 100, Loss: 42080.3633\n",
      "Epoch 200, Loss: 18965.3535\n",
      "Epoch 300, Loss: 12205.0439\n",
      "Epoch 400, Loss: 8475.0283\n",
      "Epoch 500, Loss: 6140.2407\n",
      "Epoch 600, Loss: 4809.4150\n",
      "Epoch 700, Loss: 3964.0793\n",
      "Epoch 800, Loss: 3454.9426\n"
     ]
    }
   ],
   "source": [
    "input_size = X_train_tensor.shape[1]\n",
    "hidden_size = 50\n",
    "output_size = 1\n",
    "learning_rate = 0.1\n",
    "epochs = 900\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = MLP(input_size, hidden_size, output_size)\n",
    "criterion = nn.L1Loss()  # Mean Squared Error loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Stochastic Gradient Descent\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_train_tensor)\n",
    "    loss = criterion(y_pred, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "31758f7b-6733-46e4-ab30-66f19aff3996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAPE: 16.5870%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test_tensor).numpy().flatten()\n",
    "    y_test_true = y_test_tensor.numpy().flatten()\n",
    "\n",
    "    # Compute MAPE\n",
    "    mape = np.mean(np.abs((y_test_true - y_test_pred) / y_test_true)) * 100\n",
    "\n",
    "print(f\"Test MAPE: {mape:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ab475ac1-bb42-4f5f-ab06-8c0787960c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 12.2487\n",
      "Epoch 100, Loss: 0.9679\n",
      "Epoch 200, Loss: 0.4749\n",
      "Epoch 300, Loss: 0.5493\n",
      "Epoch 400, Loss: 0.3593\n",
      "Epoch 500, Loss: 0.7961\n",
      "Epoch 600, Loss: 0.3809\n",
      "Epoch 700, Loss: 0.2344\n",
      "Epoch 800, Loss: 0.3310\n"
     ]
    }
   ],
   "source": [
    "y_train_tensor = torch.log1p(y_train_tensor)  # log(1 + y)\n",
    "y_test_tensor = torch.log1p(y_test_tensor)\n",
    "input_size = X_train_tensor.shape[1]\n",
    "hidden_size = 50\n",
    "output_size = 1\n",
    "learning_rate = 0.1\n",
    "epochs = 900\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = MLP(input_size, hidden_size, output_size)\n",
    "criterion = nn.L1Loss()  # Mean Squared Error loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Stochastic Gradient Descent\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_train_tensor)\n",
    "    loss = criterion(y_pred, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "12eb94c6-428f-44fb-bfac-379645456f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSLE: 1.4703\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test_tensor).numpy().flatten()\n",
    "    y_test_true = y_test_tensor.numpy().flatten()\n",
    "\n",
    "    # Compute RMSLE\n",
    "    rmsle = np.sqrt(np.mean((y_test_pred - y_test_true) ** 2))\n",
    "\n",
    "print(f\"Test RMSLE: {rmsle:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
